{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinged your deployment. You successfully connected to MongoDB!\n"
     ]
    }
   ],
   "source": [
    "from EvoForge.Agent.task_splitter import TaskDecompositionAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted 6 documents from 'checkpoints' collection for thread_id 'test_task_decomposition1'.\n",
      "Deleted 13 documents from 'checkpoint_writes' collection for thread_id 'test_task_decomposition1'.\n"
     ]
    }
   ],
   "source": [
    "agent = TaskDecompositionAgent(model=\"gpt-4o\", session_id=\"test_task_decomposition1\")\n",
    "agent.clear_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.rewrite_system_message(\"You decompose task/multiple tasks into one by one subtasks. The current domain is each subtask should be a project setup task such as setting up a github repo or hugging face model. Each task should only be one repo/hugging face program. Plan in very general high level, you must include the full url of the repo/hugging face model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.stream_return_graph_state(\"\"\"\n",
    "Read through this urls: https://huggingface.co/hexgrad/Kokoro-82M\n",
    "https://huggingface.co/myshell-ai/MeloTTS-Korean\n",
    "https://huggingface.co/facebook/mms-tts-yor\n",
    "https://huggingface.co/microsoft/speecht5_tts\n",
    "https://huggingface.co/facebook/mms-tts-eng\n",
    "https://huggingface.co/myshell-ai/MeloTTS-Chinese and create files for each to run each TTS models to produce an audio file. I want the text to be 'genie ai hackthon is so fun!'. Save it to audio file (best to be mp3) in the root directory  \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task_name:  Setup Kokoro-82M TTS Model\n",
      "task_context:  Create a script to load the Kokoro-82M model from Hugging Face and generate an audio file from the text 'genie ai hackthon is so fun!'. Save the output as an MP3 file in the root directory. Model URL: https://huggingface.co/hexgrad/Kokoro-82M\n",
      "task_name:  Setup MeloTTS-Korean TTS Model\n",
      "task_context:  Create a script to load the MeloTTS-Korean model from Hugging Face and generate an audio file from the text 'genie ai hackthon is so fun!'. Save the output as an MP3 file in the root directory. Model URL: https://huggingface.co/myshell-ai/MeloTTS-Korean\n",
      "task_name:  Setup MMS-TTS-Yor TTS Model\n",
      "task_context:  Create a script to load the MMS-TTS-Yor model from Hugging Face and generate an audio file from the text 'genie ai hackthon is so fun!'. Save the output as an MP3 file in the root directory. Model URL: https://huggingface.co/facebook/mms-tts-yor\n",
      "task_name:  Setup SpeechT5 TTS Model\n",
      "task_context:  Create a script to load the SpeechT5 model from Hugging Face and generate an audio file from the text 'genie ai hackthon is so fun!'. Save the output as an MP3 file in the root directory. Model URL: https://huggingface.co/microsoft/speecht5_tts\n",
      "task_name:  Setup MMS-TTS-Eng TTS Model\n",
      "task_context:  Create a script to load the MMS-TTS-Eng model from Hugging Face and generate an audio file from the text 'genie ai hackthon is so fun!'. Save the output as an MP3 file in the root directory. Model URL: https://huggingface.co/facebook/mms-tts-eng\n",
      "task_name:  Setup MeloTTS-Chinese TTS Model\n",
      "task_context:  Create a script to load the MeloTTS-Chinese model from Hugging Face and generate an audio file from the text 'genie ai hackthon is so fun!'. Save the output as an MP3 file in the root directory. Model URL: https://huggingface.co/myshell-ai/MeloTTS-Chinese\n"
     ]
    }
   ],
   "source": [
    "for step in response[\"plan\"][\"steps\"]:\n",
    "    print(\"task_name: \", step[\"task_name\"])\n",
    "    print(\"task_context: \", step[\"task_context\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yunhengzou@mariana:~/genaihackthon$ PROMPT$ bash: cd: too many arguments\n",
      "PROMPT$ Deleted 3 documents from 'checkpoints' collection for thread_id 'Setup Kokoro-82M TTS Model'.\n",
      "Deleted 6 documents from 'checkpoint_writes' collection for thread_id 'Setup Kokoro-82M TTS Model'.\n",
      "Tool call: read_webpage with args: {'url': 'https://huggingface.co/hexgrad/Kokoro-82M'}\n",
      "response\n",
      "content=[{'text': \"I'll help you create a script to load the Kokoro-82M model from Hugging Face and generate an audio file from the text 'genie ai hackthon is so fun!'. Let's first check the model page to understand how to use it properly.\", 'type': 'text'}, {'id': 'toolu_01ARyKK5wcWqNTn7ALDZTPNX', 'input': {'url': 'https://huggingface.co/hexgrad/Kokoro-82M'}, 'name': 'read_webpage', 'type': 'tool_use'}] additional_kwargs={} response_metadata={'id': 'msg_018wgvEMRyffT8S42GVJFASC', 'model': 'claude-3-7-sonnet-20250219', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 970, 'output_tokens': 129}} id='run-1c772299-4bc1-4425-89df-792460ca0f37-0' tool_calls=[{'name': 'read_webpage', 'args': {'url': 'https://huggingface.co/hexgrad/Kokoro-82M'}, 'id': 'toolu_01ARyKK5wcWqNTn7ALDZTPNX', 'type': 'tool_call'}] usage_metadata={'input_tokens': 970, 'output_tokens': 129, 'total_tokens': 1099, 'input_token_details': {'cache_read': 0, 'cache_creation': 0}}\n",
      "Setup Kokoro-82M TTS Model\n",
      "default_name\n",
      "The current progress is  10\n",
      "Tool call: execute_shell_command with args: {'shell_command': 'micromamba activate hf'}\n",
      "response\n",
      "content=[{'text': \"Now I'll activate the Hugging Face environment and create a script to use the Kokoro-82M model to generate audio from the given text.\", 'type': 'text'}, {'id': 'toolu_01HoA3qYfuCDg4rDHL3qm389', 'input': {'shell_command': 'micromamba activate hf'}, 'name': 'execute_shell_command', 'type': 'tool_use'}] additional_kwargs={} response_metadata={'id': 'msg_01Az7YHdGDo3mrSHqAVNzw6o', 'model': 'claude-3-7-sonnet-20250219', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 3318, 'output_tokens': 96}} id='run-3dec624e-e0dd-4e80-a583-afdfeefaa334-0' tool_calls=[{'name': 'execute_shell_command', 'args': {'shell_command': 'micromamba activate hf'}, 'id': 'toolu_01HoA3qYfuCDg4rDHL3qm389', 'type': 'tool_call'}] usage_metadata={'input_tokens': 3318, 'output_tokens': 96, 'total_tokens': 3414, 'input_token_details': {'cache_read': 0, 'cache_creation': 0}}\n",
      "Setup Kokoro-82M TTS Model\n",
      "default_name\n",
      "(hf) PROMPT$ The current progress is  20\n",
      "Tool call: execute_shell_command with args: {'shell_command': 'pip install -y kokoro>=0.9.2 soundfile'}\n",
      "response\n",
      "content=[{'text': \"Let's install the required packages for using the Kokoro-82M model:\", 'type': 'text'}, {'id': 'toolu_01QtQaXjRKfzTZxdt2BNuse2', 'input': {'shell_command': 'pip install -y kokoro>=0.9.2 soundfile'}, 'name': 'execute_shell_command', 'type': 'tool_use'}] additional_kwargs={} response_metadata={'id': 'msg_015XUh11ke73i9QcEDATS4Go', 'model': 'claude-3-7-sonnet-20250219', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 3427, 'output_tokens': 90}} id='run-a76c6720-3b95-42cc-9623-25f4defac24d-0' tool_calls=[{'name': 'execute_shell_command', 'args': {'shell_command': 'pip install -y kokoro>=0.9.2 soundfile'}, 'id': 'toolu_01QtQaXjRKfzTZxdt2BNuse2', 'type': 'tool_call'}] usage_metadata={'input_tokens': 3427, 'output_tokens': 90, 'total_tokens': 3517, 'input_token_details': {'cache_read': 0, 'cache_creation': 0}}\n",
      "Setup Kokoro-82M TTS Model\n",
      "default_name\n",
      "\n",
      "Usage:   \n",
      "  pip install [options] <requirement specifier> [package-index-options] ...\n",
      "  pip install [options] -r <requirements file> [package-index-options] ...\n",
      "  pip install [options] [-e] <vcs project url> ...\n",
      "  pip install [options] [-e] <local project path> ...\n",
      "  pip install [options] <archive url/path> ...\n",
      "\n",
      "no such option: -y\n",
      "(hf) PROMPT$ The current progress is  40\n",
      "Tool call: execute_shell_command with args: {'shell_command': 'pip install kokoro>=0.9.2 soundfile'}\n",
      "response\n",
      "content=[{'text': 'Let me correct the command:', 'type': 'text'}, {'id': 'toolu_01Kowmr3PJnXzZiW37pyjo6r', 'input': {'shell_command': 'pip install kokoro>=0.9.2 soundfile'}, 'name': 'execute_shell_command', 'type': 'tool_use'}] additional_kwargs={} response_metadata={'id': 'msg_01MoW2thVs8AcFmT56ZGUyVq', 'model': 'claude-3-7-sonnet-20250219', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 3630, 'output_tokens': 77}} id='run-3f71bd1b-1a68-4078-b7ad-5f77119aa529-0' tool_calls=[{'name': 'execute_shell_command', 'args': {'shell_command': 'pip install kokoro>=0.9.2 soundfile'}, 'id': 'toolu_01Kowmr3PJnXzZiW37pyjo6r', 'type': 'tool_call'}] usage_metadata={'input_tokens': 3630, 'output_tokens': 77, 'total_tokens': 3707, 'input_token_details': {'cache_read': 0, 'cache_creation': 0}}\n",
      "Setup Kokoro-82M TTS Model\n",
      "default_name\n",
      "(hf) PROMPT$ The current progress is  60\n",
      "Tool call: execute_shell_command with args: {'shell_command': 'apt-get -y install espeak-ng'}\n",
      "response\n",
      "content=[{'text': \"Let's also install espeak-ng which is required for the model:\", 'type': 'text'}, {'id': 'toolu_018YkJow2JJ4D5AMpgxWCRHX', 'input': {'shell_command': 'apt-get -y install espeak-ng'}, 'name': 'execute_shell_command', 'type': 'tool_use'}] additional_kwargs={} response_metadata={'id': 'msg_017d47Me38PrhuatfqNbk2mQ', 'model': 'claude-3-7-sonnet-20250219', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 3720, 'output_tokens': 83}} id='run-6a38f1fb-6ec1-401f-95a4-a9fdfe2611e9-0' tool_calls=[{'name': 'execute_shell_command', 'args': {'shell_command': 'apt-get -y install espeak-ng'}, 'id': 'toolu_018YkJow2JJ4D5AMpgxWCRHX', 'type': 'tool_call'}] usage_metadata={'input_tokens': 3720, 'output_tokens': 83, 'total_tokens': 3803, 'input_token_details': {'cache_read': 0, 'cache_creation': 0}}\n",
      "Setup Kokoro-82M TTS Model\n",
      "default_name\n",
      "E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n",
      "(hf) PROMPT$ The current progress is  60\n",
      "Tool call: execute_shell_command with args: {'shell_command': 'sudo apt-get -y install espeak-ng'}\n",
      "response\n",
      "content=[{'text': \"Let's try with sudo:\", 'type': 'text'}, {'id': 'toolu_016QdjjwwA52KMvg9ZchoWTg', 'input': {'shell_command': 'sudo apt-get -y install espeak-ng'}, 'name': 'execute_shell_command', 'type': 'tool_use'}] additional_kwargs={} response_metadata={'id': 'msg_01EGpMqy5eJ5p6pnZBdK88Li', 'model': 'claude-3-7-sonnet-20250219', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 3872, 'output_tokens': 75}} id='run-666eb7db-10b3-4260-b7d4-b62eb7915d5d-0' tool_calls=[{'name': 'execute_shell_command', 'args': {'shell_command': 'sudo apt-get -y install espeak-ng'}, 'id': 'toolu_016QdjjwwA52KMvg9ZchoWTg', 'type': 'tool_call'}] usage_metadata={'input_tokens': 3872, 'output_tokens': 75, 'total_tokens': 3947, 'input_token_details': {'cache_read': 0, 'cache_creation': 0}}\n",
      "Setup Kokoro-82M TTS Model\n",
      "default_name\n",
      "[sudo] password for yunhengzou: "
     ]
    }
   ],
   "source": [
    "tasks = response[\"plan\"][\"steps\"]\n",
    "\n",
    "\n",
    "from EvoForge import EvoForge  \n",
    "evoforge_client = EvoForge()\n",
    "def run_EvoForge_Agent(session:str,task:str):\n",
    "    agent = evoforge_client.spawn_setup_agent(session)\n",
    "    agent.clear_memory()\n",
    "    result = agent.stream_return_graph_state(task)\n",
    "    return result\n",
    "\n",
    "run_EvoForge_Agent(tasks[0][\"task_name\"],tasks[0][\"task_context\"])\n",
    "\n",
    "# from concurrent.futures import ThreadPoolExecutor\n",
    "# with ThreadPoolExecutor(max_workers=3) as executor:\n",
    "#     futures = [\n",
    "#         executor.submit(run_EvoForge_Agent, task[\"task_name\"], task[\"task_context\"])\n",
    "#         for task in tasks\n",
    "#     ]\n",
    "#     results = [future.result() for future in futures]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
